{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc223b99-d7a3-48e1-8874-7c7c299e485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592b228-40f5-4775-be18-621b008a34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a489637-c47b-4490-aa87-22ead8217868",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_hf[\"transformer.wpe.weight\"].view(-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee71927-968d-457c-b65d-fce887e06fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(sd_hf[\"transformer.wpe.weight\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96dbd2-4bac-462e-ac65-4a9daa61b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 150])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 200])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9f9af-c2c5-457b-a2dc-1494dc69cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sd_hf[\"transformer.h.1.attn.c_attn.weight\"][:300,:300], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59722a91-87bb-4561-8b63-d1bc49038dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4605b7-ddf5-476b-a714-773d4765254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from train_gpt2 import GPT\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "prompt = \"Hello, I'm a language model,\"\n",
    "tokens = torch.tensor(tokenizer.encode(prompt))\n",
    "\n",
    "model = GPT.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8734ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "with torch.no_grad():\n",
    "    sample_tokens = tokens.repeat(num_return_sequences, 1)\n",
    "    for _ in range(max_length):\n",
    "        logits = model(sample_tokens)\n",
    "        logits, top_indices = torch.topk(logits[:,-1,:], k=100, dim=-1)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        sampled_indices = torch.multinomial(probs, num_samples=1)  \n",
    "        next_token_indices = torch.gather(top_indices, dim=1, index=sampled_indices)\n",
    "        sample_tokens = torch.cat([sample_tokens, next_token_indices], 1)\n",
    "        \n",
    "    for sample_token in sample_tokens:\n",
    "        print(tokenizer.decode(sample_token))\n",
    "        print(\"-\"*40)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640488ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_learning_venv)",
   "language": "python",
   "name": "ml_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
